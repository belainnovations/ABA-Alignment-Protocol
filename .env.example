# ABA Alignment Protocol - Configuration
# Rename this file to .env and fill in your keys.

# Required for Phase 2: Automated Rewriting
GOOGLE_API_KEY=your_google_api_key_here

# ============================================================
# MODEL CONFIGURATIONS
# ============================================================
# Define up to 4 configs. Select which to use via:
#   python -m src.aba_protocol.rewrite --config 1
#   python -m src.aba_protocol.rewrite --config 2
#   etc.
# ============================================================

# --- CONFIG 1: Pro + High Thinking (Default, Current v1.4 setup) ---
CONFIG1_MODEL=gemini-3-pro-preview
CONFIG1_THINKING_LEVEL=high
CONFIG1_DESCRIPTION=Pro + High Thinking (Maximum Quality)

# --- CONFIG 2: Pro + Best Practices (Vertex Compatible) ---
CONFIG2_MODEL=gemini-2.5-pro
CONFIG2_THINKING_LEVEL=none
CONFIG2_DESCRIPTION="Vertex AI Pro (Industrial Stable)"

# --- CONFIG 3: Flash + Low Thinking ---
CONFIG3_MODEL=gemini-3-flash-preview
CONFIG3_THINKING_LEVEL=low
CONFIG3_DESCRIPTION=Flash + Low Thinking (Fastest, Cheapest)

# ---# Config 4: Flash + High Thinking (Pivot)
CONFIG4_MODEL=gemini-2.0-flash-thinking-exp-01-21
CONFIG4_THINKING_LEVEL=high
CONFIG4_DESCRIPTION="Flash High Thinking (Speed/Quality Balance)"

# --- Vertex AI Configuration (Industrial) ---
GOOGLE_CLOUD_PROJECT=gen-lang-client-xxx
GOOGLE_CLOUD_LOCATION=us-central1
# Path to your Service Account JSON Key (Required if gcloud is missing)
GOOGLE_APPLICATION_CREDENTIALS=./gen-lang-client-xxx.json

# ============================================================
# THINKING LEVEL OPTIONS
# ============================================================
# "high"    - Maximum reasoning depth
# "low"     - Minimal reasoning, lower latency
# "medium"  - Balanced (Flash only)
# "minimal" - Absolute minimum (Flash only)
# ============================================================

# Optional: Other providers (not currently used)
# OPENAI_API_KEY=
# ANTHROPIC_API_KEY=
